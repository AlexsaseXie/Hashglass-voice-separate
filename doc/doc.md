# 音频大作业——人声分离器实验报告

石耕源 2015013219 冯玉彤 2015013202 谢运帷 2015013185

---

### 一、人声分离系统工作流程

我们搭建的人声分离器系统，借鉴了作业要求中给出的参考论文1）Music Source Separation Using Stacked Hourglass Networks。此篇文章指导我们完成了人声分离中的重要部分——理由一个堆叠的Hourglass神经网络，将人声和背景音乐的特征从混合的音乐特征中分离出来，得到两幅mask。随后，我们进行这个mask的优化，得到人声和背景音乐两张频幅图特征。最后，我们依靠原音乐的频幅图的复角信息，应用到人声和背景的频幅图上，还原出人声和背景的音频。

1）Stacked Hourglass Network

![network_structure](C:\Users\xyw\Desktop\数字媒体：多媒体\音频大作业\Hourglass\doc\network_structure.png)

上图展示了此篇文章的网络结构：首先，我们的输入是单通道的原音乐的频幅图（1\*512\*64），经过一系列初始卷积核，提取出256张特征图（256\*512\*64），输入到Hourglass模块中。经过一个Hourglass模块，它会分析出两张和输入频幅图相同大小的mask（2\*512\*64），分别对应人声和背景的mask的估计，这个mask和原混合音乐的频谱图的乘积（对应元素相乘）即为整个网络预测的人声/背景的预测频幅图。与此同时，Hourglass模块还会计算出一个和原输入（256\*512\*64）相同大小的特征，输入到下一个Hourglass模块中。

![hourglass](C:\Users\xyw\Desktop\数字媒体：多媒体\音频大作业\Hourglass\doc\hourglass.png)

文章中使用的Hourglass模块就如上图所示，它先通过池化和卷积核将特征图的分辨率降低，再通过上采样将特征还原到与输入相同的大小。整个过程伴随着浅层信息直接和深层信息相加的过程，可以很好的保留原始的特征信息。最后通过1\*1卷积，将输出和下一层Hourglass输入的通道规范化。文中特别提到，网络中没有使用BN和Sigmoid等等规范化函数，这是因为这些函数会让梯度值下降，让整体训练的过程变慢，从结果上来看也不会使准确率提升。

训练过程所需的Loss函数也自然而然地可以给出，即是根据所有Hourglass模块给出的mask得到的预测频谱图和目标频谱图之间的L1范数差异之和。即使在应用中，只有最后一个模块的预测才与最终的预测结果相关，这样的Loss函数还是可以加速训练过程，使网络快速的收敛。

我们的实现基本是按照文中所说的过程实现的。整个网络的训练过程可以在多GPU的机器上进行。

